{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Project Tutorial\n",
    "\n",
    "In this project you will practice with a dataset to create a review classifier for the Google Play store.\n",
    "\n",
    "In this case, we have only 3 variables: 2 predictors and a dichotomous label. Of the two predictors, we are really only interested in the comment part, since the fact of classifying a comment as positive or negative will depend on its content, not on the application from which it was written. Therefore, the package_name variable should be removed.\n",
    "\n",
    "When we work with text, as in this case, it does not make sense to do an EDA, the process is different, since the only variable we are interested in is the one that contains the text. In other cases where the text is part of a complex set with other numeric predictor variables and the prediction objective is different, then it makes sense to apply an EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package_name</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>privacy at least put some option appear offli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>messenger issues ever since the last update, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>profile any time my wife or anybody has more ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>the new features suck for those of us who don...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>forced reload on uploading pic on replying co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          package_name                                             review  \\\n",
       "0  com.facebook.katana   privacy at least put some option appear offli...   \n",
       "1  com.facebook.katana   messenger issues ever since the last update, ...   \n",
       "2  com.facebook.katana   profile any time my wife or anybody has more ...   \n",
       "3  com.facebook.katana   the new features suck for those of us who don...   \n",
       "4  com.facebook.katana   forced reload on uploading pic on replying co...   \n",
       "\n",
       "   polarity  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_url = 'https://improved-yodel-7vr4wwrp4jv9cwp6q.github.dev/'\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>privacy at least put some option appear offli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>messenger issues ever since the last update, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profile any time my wife or anybody has more ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the new features suck for those of us who don...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forced reload on uploading pic on replying co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  polarity\n",
       "0   privacy at least put some option appear offli...         0\n",
       "1   messenger issues ever since the last update, ...         0\n",
       "2   profile any time my wife or anybody has more ...         0\n",
       "3   the new features suck for those of us who don...         0\n",
       "4   forced reload on uploading pic on replying co...         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Data Set up: dropping non-relevant columns \"package_name\"\n",
    "\n",
    "df.drop([\"package_name\"], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>privacy at least put some option appear offlin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>messenger issues ever since the last update, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profile any time my wife or anybody has more t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the new features suck for those of us who don'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forced reload on uploading pic on replying com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>loved it i loooooooooooooovvved it because it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>all time legendary game the birthday party lev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>ads are way to heavy listen to the bad reviews...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>fun works perfectly well. ads aren't as annoyi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>they're everywhere i see angry birds everywher...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  polarity\n",
       "0    privacy at least put some option appear offlin...         0\n",
       "1    messenger issues ever since the last update, i...         0\n",
       "2    profile any time my wife or anybody has more t...         0\n",
       "3    the new features suck for those of us who don'...         0\n",
       "4    forced reload on uploading pic on replying com...         0\n",
       "..                                                 ...       ...\n",
       "886  loved it i loooooooooooooovvved it because it ...         1\n",
       "887  all time legendary game the birthday party lev...         1\n",
       "888  ads are way to heavy listen to the bad reviews...         0\n",
       "889  fun works perfectly well. ads aren't as annoyi...         1\n",
       "890  they're everywhere i see angry birds everywher...         1\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing spaces and converting the text to lowercase\n",
    "\n",
    "df[\"review\"] = df[\"review\"].str.strip().str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor 'review' Text Data Vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec_model = CountVectorizer(stop_words = \"english\")\n",
    "\n",
    "# Vectorize the 'review' column before splitting\n",
    "X_vec = vec_model.fit_transform(df['review']).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Split\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# STEP 4) Data Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, df['polarity'], test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 3721)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " gaussianNB Accuracy (test): 0.8044692737430168\n",
      "\n",
      " gaussianNB Accuracy (train): 0.9859550561797753\n",
      "\n",
      " \n",
      " gaussianNB f1_score (test): 0.8044692737430168\n",
      "\n",
      " gaussianNB f1_score (train): 0.9859550561797753\n",
      "\n",
      " \n",
      " gaussianNB precision (test): 0.8044692737430168\n",
      "\n",
      " gaussianNB precision (train): 0.9859550561797753\n",
      "\n",
      " \n",
      " gaussianNB recall (test): 0.8044692737430168\n",
      "\n",
      " gaussianNB recall (train): 0.9859550561797753\n"
     ]
    }
   ],
   "source": [
    "# STEP 5) GaussianNB model\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussianNB_model = GaussianNB()\n",
    "gaussianNB_model.fit(X_train, y_train)\n",
    "\n",
    "gaussianNB_y_pred_test = gaussianNB_model.predict(X_test)\n",
    "\n",
    "gaussianNB_y_pred_train = gaussianNB_model.predict(X_train) \n",
    "\n",
    "# Evaluation:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "print(f\"\\n \\n gaussianNB Accuracy (test): {accuracy_score(y_test, gaussianNB_y_pred_test)}\")\n",
    "print(f\"\\n gaussianNB Accuracy (train): {accuracy_score(y_train, gaussianNB_y_pred_train)}\") \n",
    "print(f\"\\n \\n gaussianNB f1_score (test): {f1_score(y_test, gaussianNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n gaussianNB f1_score (train): {f1_score(y_train, gaussianNB_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n gaussianNB precision (test): {precision_score(y_test, gaussianNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n gaussianNB precision (train): {precision_score(y_train, gaussianNB_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n gaussianNB recall (test): {recall_score(y_test, gaussianNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n gaussianNB recall (train): {recall_score(y_train, gaussianNB_y_pred_train, average='micro')}\")\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "dump(gaussianNB_model, open(\"gaussianNB_model.sav\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Best hyperparameters: {'priors': None, 'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "# STEP 5.B) Optimized GaussianNB model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "hyperparams = {\n",
    "    \"priors\": ['n_classes', None],\n",
    "    \"var_smoothing\": [float, 1e-9],\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(gaussianNB_model, hyperparams, scoring=['accuracy', 'f1_micro', 'precision_micro', 'recall_micro'], refit='accuracy', cv=10) \n",
    "grid\n",
    "\n",
    "# Identifying best hyperparams\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"GaussianNB Best hyperparameters: {grid.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " gaussianNB Accuracy (test): 0.8044692737430168\n",
      "\n",
      " gaussianNB Accuracy (train): 0.9859550561797753\n",
      "\n",
      " \n",
      " gaussianNB f1_score (test): 0.8044692737430168\n",
      "\n",
      " gaussianNB f1_score (train): 0.9859550561797753\n",
      "\n",
      " \n",
      " gaussianNB precision (test): 0.8044692737430168\n",
      "\n",
      " gaussianNB precision (train): 0.9859550561797753\n",
      "\n",
      " \n",
      " gaussianNB recall (test): 0.8044692737430168\n",
      "\n",
      " gaussianNB recall (train): 0.9859550561797753\n",
      "\n",
      " No improvement observed after gaussianNB optimization\n"
     ]
    }
   ],
   "source": [
    "# STEP 5.C) Optimized GaussianNB model\n",
    "\n",
    "# Running the Optimized GaussianNB model\n",
    "\n",
    "optimized_gaussianNB_model = GaussianNB(priors = None, var_smoothing = 1e-09)\n",
    "\n",
    "optimized_gaussianNB_model.fit(X_train, y_train)\n",
    "\n",
    "optimized_gaussianNB_model_y_pred_test = gaussianNB_model.predict(X_test)\n",
    "\n",
    "optimized_gaussianNB_model_y_pred_train = gaussianNB_model.predict(X_train) \n",
    "\n",
    "\n",
    "print(f\"\\n \\n gaussianNB Accuracy (test): {accuracy_score(y_test, optimized_gaussianNB_model_y_pred_test)}\")\n",
    "print(f\"\\n gaussianNB Accuracy (train): {accuracy_score(y_train, optimized_gaussianNB_model_y_pred_train)}\") \n",
    "print(f\"\\n \\n gaussianNB f1_score (test): {f1_score(y_test, optimized_gaussianNB_model_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n gaussianNB f1_score (train): {f1_score(y_train, optimized_gaussianNB_model_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n gaussianNB precision (test): {precision_score(y_test, optimized_gaussianNB_model_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n gaussianNB precision (train): {precision_score(y_train, optimized_gaussianNB_model_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n gaussianNB recall (test): {recall_score(y_test, optimized_gaussianNB_model_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n gaussianNB recall (train): {recall_score(y_train, optimized_gaussianNB_model_y_pred_train, average='micro')}\")\n",
    "\n",
    "print(\"\\n No improvement observed after gaussianNB optimization\")\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "dump(optimized_gaussianNB_model, open(\"optimized_gaussianNB_model.sav\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " MultinomialNB Accuracy (test): 0.776536312849162\n",
      "\n",
      " MultinomialNB Accuracy (train): 0.9578651685393258\n",
      "\n",
      " \n",
      " MultinomialNB f1_score (test): 0.776536312849162\n",
      "\n",
      " MultinomialNB f1_score (train): 0.9578651685393258\n",
      "\n",
      " \n",
      " MultinomialNB precision (test): 0.776536312849162\n",
      "\n",
      " MultinomialNB precision (train): 0.9578651685393258\n",
      "\n",
      " \n",
      " MultinomialNB recall (test): 0.776536312849162\n",
      "\n",
      " MultinomialNB recall (train): 0.9578651685393258\n"
     ]
    }
   ],
   "source": [
    "# Multinomial model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multinomialNB_model = MultinomialNB()\n",
    "multinomialNB_model.fit(X_train, y_train)\n",
    "\n",
    "multinomialNB_y_pred_test = multinomialNB_model.predict(X_test)\n",
    "\n",
    "multinomialNB_y_pred_train = multinomialNB_model.predict(X_train) \n",
    "\n",
    "# Evaluation:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "print(f\"\\n \\n MultinomialNB Accuracy (test): {accuracy_score(y_test, multinomialNB_y_pred_test)}\")\n",
    "print(f\"\\n MultinomialNB Accuracy (train): {accuracy_score(y_train, multinomialNB_y_pred_train)}\") \n",
    "print(f\"\\n \\n MultinomialNB f1_score (test): {f1_score(y_test, multinomialNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n MultinomialNB f1_score (train): {f1_score(y_train, multinomialNB_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n MultinomialNB precision (test): {precision_score(y_test, multinomialNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n MultinomialNB precision (train): {precision_score(y_train, multinomialNB_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n MultinomialNB recall (test): {recall_score(y_test, multinomialNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n MultinomialNB recall (train): {recall_score(y_train, multinomialNB_y_pred_train, average='micro')}\")\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "dump(multinomialNB_model, open(\"multinomialNB_model.sav\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomialNB Model Best hyperparameters: {'alpha': np.float64(0.6122448979685715), 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "# Optimized Multinomial model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "hyperparams = {\n",
    "    \"alpha\": np.linspace(0.00000000001,10),\n",
    "    \"fit_prior\": [False, True],\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(multinomialNB_model, hyperparams, scoring=['accuracy', 'f1_micro', 'precision_micro', 'recall_micro'], refit='accuracy', cv=10) \n",
    "\n",
    "\n",
    "# Identifying best hyperparams\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"multinomialNB Model Best hyperparameters: {grid.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " MultinomialNB Accuracy (test): 0.776536312849162\n",
      "\n",
      " MultinomialNB Accuracy (train): 0.9662921348314607\n",
      "\n",
      " \n",
      " MultinomialNB f1_score (test): 0.776536312849162\n",
      "\n",
      " MultinomialNB f1_score (train): 0.9662921348314607\n",
      "\n",
      " \n",
      " MultinomialNB precision (test): 0.776536312849162\n",
      "\n",
      " MultinomialNB precision (train): 0.9662921348314607\n",
      "\n",
      " \n",
      " MultinomialNB recall (test): 0.776536312849162\n",
      "\n",
      " MultinomialNB recall (train): 0.9662921348314607\n"
     ]
    }
   ],
   "source": [
    "# Optimized Multinomial model\n",
    "\n",
    "# Testing the optimized Multinomial model\n",
    "\n",
    "optimized_multinomialNB_model = MultinomialNB(alpha = 0.6122448979685715, fit_prior = False)\n",
    "optimized_multinomialNB_model.fit(X_train, y_train)\n",
    "\n",
    "optimized_multinomialNB_y_pred_test = optimized_multinomialNB_model.predict(X_test)\n",
    "\n",
    "optimized_multinomialNB_y_pred_train = optimized_multinomialNB_model.predict(X_train) \n",
    "\n",
    "# Evaluation:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "print(f\"\\n \\n MultinomialNB Accuracy (test): {accuracy_score(y_test, optimized_multinomialNB_y_pred_test)}\")\n",
    "print(f\"\\n MultinomialNB Accuracy (train): {accuracy_score(y_train, optimized_multinomialNB_y_pred_train)}\") \n",
    "print(f\"\\n \\n MultinomialNB f1_score (test): {f1_score(y_test, optimized_multinomialNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n MultinomialNB f1_score (train): {f1_score(y_train, optimized_multinomialNB_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n MultinomialNB precision (test): {precision_score(y_test, optimized_multinomialNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n MultinomialNB precision (train): {precision_score(y_train, optimized_multinomialNB_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n MultinomialNB recall (test): {recall_score(y_test, optimized_multinomialNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n MultinomialNB recall (train): {recall_score(y_train, optimized_multinomialNB_y_pred_train, average='micro')}\")\n",
    "\n",
    "print(\"\\n No improvement observed after gaussianNB optimization\")\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "dump(multinomialNB_model, open(\"optimized_multinomialNB_model.sav\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " BernoulliNB_model Accuracy (test): 0.7597765363128491\n",
      "\n",
      " BernoulliNB_model Accuracy (train): 0.9030898876404494\n",
      "\n",
      " \n",
      " BernoulliNB_model f1_score (test): 0.7597765363128491\n",
      "\n",
      " BernoulliNB_model f1_score (train): 0.9030898876404494\n",
      "\n",
      " \n",
      " BernoulliNB_model precision (test): 0.7597765363128491\n",
      "\n",
      " BernoulliNB_model precision (train): 0.9030898876404494\n",
      "\n",
      " \n",
      " BernoulliNB_model recall (test): 0.7597765363128491\n",
      "\n",
      " BernoulliNB_model recall (train): 0.9030898876404494\n"
     ]
    }
   ],
   "source": [
    "# STEP 7) BernoulliNB model\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "BernoulliNB_model = BernoulliNB()\n",
    "BernoulliNB_model.fit(X_train, y_train)\n",
    "\n",
    "BernoulliNB_y_pred_test = BernoulliNB_model.predict(X_test)\n",
    "\n",
    "BernoulliNB_y_pred_train = BernoulliNB_model.predict(X_train) \n",
    "\n",
    "# Evaluation:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "print(f\"\\n \\n BernoulliNB_model Accuracy (test): {accuracy_score(y_test, BernoulliNB_y_pred_test)}\")\n",
    "print(f\"\\n BernoulliNB_model Accuracy (train): {accuracy_score(y_train, BernoulliNB_y_pred_train)}\") \n",
    "print(f\"\\n \\n BernoulliNB_model f1_score (test): {f1_score(y_test, BernoulliNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n BernoulliNB_model f1_score (train): {f1_score(y_train, BernoulliNB_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n BernoulliNB_model precision (test): {precision_score(y_test, BernoulliNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n BernoulliNB_model precision (train): {precision_score(y_train, BernoulliNB_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n BernoulliNB_model recall (test): {recall_score(y_test, BernoulliNB_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n BernoulliNB_model recall (train): {recall_score(y_train, BernoulliNB_y_pred_train, average='micro')}\")\n",
    "\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "dump(BernoulliNB_model, open(\"BernoulliNB_model.sav\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
